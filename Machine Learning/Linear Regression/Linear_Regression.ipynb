{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **线性回归Python底层实现**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **实验目标**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过本案例的学习和课后作业的练习：\n",
    "\n",
    "1. 了解最优线性回归模型参数的解析解的求解过程；\n",
    "2. 帮助大家加深线性回归模型的基本求解原理；\n",
    "3. 掌握通过一个简单的工具包调用过程帮助大家掌握快速实现线性回归模型的方法。\n",
    "\n",
    "你也可以将本案例相关的 ipynb 学习笔记分享到[ AI Gallery Notebook](https://marketplace.huaweicloud.com/markets/aihub/notebook/list/) 版块获得[成长值](https://marketplace.huaweicloud.com/markets/aihub/article/detail/?content_id=9b8d7e7a-a150-449e-ac17-2dcf76d8b492)，分享方法请查看[此文档](https://marketplace.huaweicloud.com/markets/aihub/article/detail/?content_id=8afec58a-b797-4bf9-acca-76ed512a3acb)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **案例内容介绍**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归是机器学习中最基本的模型，用来拟合自变量和因变量之间呈现线性关系的数据，当自变量只有一个时我们称使用的回归模型是一元线性回归模型，当自变量有多个时称使用的回归模型是多元线性回归模型。根据已知数据，求解线性回归模型的参数最常用到的方法是最小二乘法，求解使得损失函数取得最小值的模型参数的解析解或者使用梯度下降算法求得最优的模型参数。\n",
    "\n",
    "本案例推荐的理论学习视频：\n",
    "\n",
    "- [《AI技术领域课程--机器学习》 线性回归 ](https://education.huaweicloud.com/courses/course-v1:HuaweiX+CBUCNXE086+Self-paced/courseware/ab6a6a573d494a06997714b95aa9069d/de35c1b844f64c91a077087e7a7d6f46/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **注意事项**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 如果您是第一次使用 JupyterLab，请查看[《ModelArts JupyterLab使用指导》](https://marketplace.huaweicloud.com/markets/aihub/article/detail/?content_id=03676d0a-0630-4a3f-b62c-07fba43d2857)了解使用方法；\n",
    "\n",
    "2. 如果您在使用 JupyterLab 过程中碰到报错，请参考[《ModelArts JupyterLab常见问题解决办法》](https://marketplace.huaweicloud.com/markets/aihub/article/detail/?content_id=9ad8ce7d-06f7-4394-80ef-4dbf6cfb4be1)尝试解决问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **实验步骤**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据集说明：**   本实验使用的是构造的数据集，数据构造的过程在代码中有明确显示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、一元线性回归Python底层实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.714285714285714 1.4285714285714306\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f5c75a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 一元线性回归的实现\n",
    "\n",
    "# 导入matplotlib库，主要用于可视化\n",
    "import numpy as np\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 引入本地字体文件，否则中文会有乱码\n",
    "# font_set = FontProperties(fname=r\"./work/ simsun.ttc\", size=12)\n",
    "\n",
    "# 构造用于训练的数据集\n",
    "x_train = [4, 8, 5, 10, 12]\n",
    "y_train = [20, 50, 30, 70, 60]\n",
    "\n",
    "\n",
    "# 画图函数\n",
    "\n",
    "\n",
    "def draw(x_train, y_train):\n",
    "    plt.scatter(x_train, y_train)\n",
    "\n",
    "\n",
    "# 定义函数求得斜率w和截距b\n",
    "# 使用最小二乘法对斜率和截距求导并使得导数值等于0求解出斜率和截距\n",
    "\n",
    "\n",
    "def fit(x_train, y_train):\n",
    "    size = len(x_train)\n",
    "    numerator = 0  # 初始化分子\n",
    "    denominator = 0  # 初始化分母\n",
    "    for i in range(size):\n",
    "        numerator += (x_train[i] - np.mean(x_train)) * \\\n",
    "                     (y_train[i] - np.mean(y_train))\n",
    "        denominator += (x_train[i] - np.mean(x_train)) ** 2\n",
    "    w = numerator / denominator\n",
    "    b = np.mean(y_train) - w * np.mean(x_train)\n",
    "    return w, b\n",
    "\n",
    "\n",
    "# 根据斜率w和截距b，输入x计算输出值\n",
    "\n",
    "\n",
    "def predict(x, w, b):\n",
    "    # 预测模型\n",
    "    y = w * x + b\n",
    "    return y\n",
    "\n",
    "\n",
    "# 根据W,B画图\n",
    "\n",
    "\n",
    "def fit_line(w, b):\n",
    "    # 测试集进行测试，并作图\n",
    "    # linspace 创建等差数列的函数    #numpy.limspace(start,stop,num,endpoint=True,retstep=False,dtype=None,axis=0#)\n",
    "    x = np.linspace(4, 15, 9)\n",
    "    y = w * x + b\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    draw(x_train, y_train)\n",
    "    w, b = fit(x_train, y_train)\n",
    "    print(w, b)  # 输出斜率和截距\n",
    "fit_line(w, b)  # 绘制预测函数图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、多元线性回归的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [[ 3  2  9 20]\n",
      "\n",
      " [ 4 10  2 72]\n",
      "\n",
      " [ 3  4  9 21]\n",
      "\n",
      " [12  3  4 20]] \n",
      "\n",
      "\n",
      "\n",
      "X: [[ 1.  3.  2.  9.]\n",
      "\n",
      " [ 1.  4. 10.  2.]\n",
      "\n",
      " [ 1.  3.  4.  9.]\n",
      "\n",
      " [ 1. 12.  3.  4.]] \n",
      "\n",
      "\n",
      "\n",
      "Y: [[20 72 21 20]] \n",
      "\n",
      "\n",
      "\n",
      "B: [[98.70689655]\n",
      "\n",
      " [-4.19827586]\n",
      "\n",
      " [ 0.5       ]\n",
      "\n",
      " [-7.45689655]] \n",
      "\n",
      "\n",
      "\n",
      "1,60,60,60预测结果： [[-570.60344828]] \n",
      "\n",
      "\n",
      "\n",
      "R2 [[1.]]\n"
     ]
    }
   ],
   "source": [
    "# 多元线性回归的实现\n",
    "# 导入模块\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 构造数据，前三列表示自变量X，最后一列表示因变量Y\n",
    "data = np.array([[3, 2, 9, 20],\n",
    "                 [4, 10, 2, 72],\n",
    "                 [3, 4, 9, 21],\n",
    "                 [12, 3, 4, 20]])\n",
    "print(\"data:\", data, \"\\n\")\n",
    "\n",
    "X = data[:, :-1]\n",
    "Y = data[:, -1]\n",
    "\n",
    "X = np.mat(np.c_[np.ones(X.shape[0]), X])  # 为系数矩阵增加常数项系数\n",
    "Y = np.mat(Y)  # 数组转化为矩阵\n",
    "\n",
    "print(\"X:\", X, \"\\n\")\n",
    "print(\"Y:\", Y, \"\\n\")\n",
    "\n",
    "# 根据最小二乘法的目标函数求导为0得到最优参数向量B的解析解公式如下，可以直接求取最优参数向量\n",
    "B = np.linalg.inv(X.T * X) * (X.T) * (Y.T)\n",
    "print(\"B:\", B, \"\\n\")  # 输出系数,第一项为常数项，其他为回归系数\n",
    "print(\"1,60,60,60预测结果：\", np.mat([1, 60, 60, 60]) * B, \"\\n\")  # 预测结果\n",
    "\n",
    "# 相关系数\n",
    "Q_e = 0\n",
    "Q_E = 0\n",
    "Y_mean = np.mean(Y)\n",
    "for i in range(Y.size):\n",
    "    Q_e += pow(np.array((Y.T)[i] - X[i] * B), 2)\n",
    "    Q_E += pow(np.array(X[i] * B) - Y_mean, 2)\n",
    "R2 = Q_E / (Q_e + Q_E)\n",
    "print(\"R2\", R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、线性回归第三方库实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.39207048 -6.03524229]\n",
      "22.907488986784166\n",
      "0.7433664583546766\n"
     ]
    }
   ],
   "source": [
    "# 导入sklearn下的LinearRegression 方法\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# 构造用于训练的数据集\n",
    "x_train = np.array([[2, 4], [5, 8], [5, 9], [7, 10], [9, 12]])\n",
    "y_train = np.array([20, 50, 30, 70, 60])\n",
    "\n",
    "# 训练模型并输出模型系数和训练结果\n",
    "model.fit(x_train, y_train)\n",
    "# fit(x,y,sample_weight=None)x:训练集 y:目标值 sample_weight:每个样本的个数\n",
    "# coef_ 系数w,intercept_截距\n",
    "print(model.coef_)  # 输出系数w\n",
    "print(model.intercept_)  # 输出截距b\n",
    "print(model.score(x_train, y_train))  # 输出模型的评估分数R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上是 线性回归 的实现方法，受限于篇幅原因，本案例未完全覆盖 线性回归 的全部操作，欢迎你将更全面的 线性回归 学习笔记分享到[ AI Gallery Notebook](https://marketplace.huaweicloud.com/markets/aihub/notebook/list/) 版块获得[成长值](https://marketplace.huaweicloud.com/markets/aihub/article/detail/?content_id=9b8d7e7a-a150-449e-ac17-2dcf76d8b492)，分享方法请查看[此文档](https://marketplace.huaweicloud.com/markets/aihub/article/detail/?content_id=8afec58a-b797-4bf9-acca-76ed512a3acb)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **作业**\n",
    "\n",
    "请你利用本实验中学到的知识点，完成以下编程题："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [请你尝试修改 LogisticRegression() 函数的 penalty（正则化选择）参数的不同取值，看看该参数的修改对模型会有怎样的影响。](https://marketplace.huaweicloud.com/markets/aihub/notebook/detail/?id=9de6965a-1e50-4e95-bcdd-bb59057cef11)\n",
    "2. [请你尝试修改 LogisticRegression() 函数的 solver（优化算法选择）参数的不同取值，看看该参数的修改对模型会有怎样的影响。](https://marketplace.huaweicloud.com/markets/aihub/notebook/detail/?id=c1267237-10cd-44b9-a315-b692510ecabb)\n",
    "3. [根据乳腺癌数据集，基于Sklearn实现一个逻辑回归模型预测病人是否得了癌症。](https://marketplace.huaweicloud.com/markets/aihub/notebook/detail/?id=d3e592ad-99fd-43ee-8f14-5279a9f50243)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XGBoost-Sklearn",
   "language": "python",
   "name": "xgboost-sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
